# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The section authors, The jamovi Group, and Sebastian Jentschke (curating this documentation). This work is licensed under a Creative Commons Attribution-Non Commercial 4.0 International License.
# This file is distributed under the same license as the jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: jamovi\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-08-18 23:13+0200\n"
"PO-Revision-Date: 2020-08-10 17:57+0000\n"
"Language-Team: Norwegian Bokmål (https://www.transifex.com/jamovi/teams/111618/nb/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: nb\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: ../../lsj/Ch16_Bayes_2.rst:4
msgid "Bayesian hypothesis tests"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:6
msgid ""
"In Chapter `Hypothesis testing <Ch09_HypothesisTesting.html#hypothesis-"
"testing>`__ I described the orthodox approach to hypothesis testing. It took"
" an entire chapter to describe, because null hypothesis testing is a very "
"elaborate contraption that people find very hard to make sense of. In "
"contrast, the Bayesian approach to hypothesis testing is incredibly simple. "
"Let’s pick a setting that is closely analogous to the orthodox scenario. "
"There are two hypotheses that we want to compare, a null hypothesis *h*\\ "
":sub:`0` and an alternative hypothesis *h*\\ :sub:`1`. Prior to running the "
"experiment we have some beliefs *P*\\ (h) about which hypotheses are true. "
"We run an experiment and obtain data *d*. Unlike frequentist statistics, "
"Bayesian statistics does allow us to talk about the probability that the "
"null hypothesis is true. Better yet, it allows us to calculate the "
"**posterior probability of the null hypothesis**, using Bayes’ rule:"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:20
msgid "P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:22
msgid ""
"This formula tells us exactly how much belief we should have in the null "
"hypothesis after having observed the data *d*. Similarly, we can work out "
"how much belief to place in the alternative hypothesis using essentially the"
" same equation. All we do is change the subscript:"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:27
msgid "P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:29
msgid ""
"It’s all so simple that I feel like an idiot even bothering to write these "
"equations down, since all I’m doing is copying Bayes rule from the previous "
"section.\\ [#]_"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:34
msgid "The Bayes factor"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:36
msgid ""
"In practice, most Bayesian data analysts tend not to talk in terms of the "
"raw posterior probabilities *P*\\ (h\\ :sub:`0`\\|d) and *P*\\ (h\\ "
":sub:`1`\\|d). Instead, we tend to talk in terms of the **posterior odds** "
"ratio. Think of it like betting. Suppose, for instance, the posterior "
"probability of the null hypothesis is 25%, and the posterior probability of "
"the alternative is 75%. The alternative hypothesis is three times as "
"probable as the null, so we say that the *odds* are 3:1 in favour of the "
"alternative. Mathematically, all we have to do to calculate the posterior "
"odds is divide one posterior probability by the other"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:46
msgid "\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:48
msgid "Or, to write the same thing in terms of the equations above"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:50
msgid ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times "
"\\frac{P(h_1)}{P(h_0)}"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:52
msgid ""
"Actually, this equation is worth expanding on. There are three different "
"terms here that you should know. On the left hand side, we have the "
"posterior odds, which tells you what you believe about the relative "
"plausibilty of the null hypothesis and the alternative hypothesis *after* "
"seeing the data. On the right hand side, we have the **prior odds**, which "
"indicates what you thought *before* seeing the data. In the middle, we have "
"the **Bayes factor**, which describes the amount of evidence provided by the"
" data"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:61
msgid ""
"\\begin{array}{ccccc}\\displaystyle \\frac{P(h_1 | d)}{P(h_0 | d)} & = & "
"\\displaystyle\\frac{P(d|h_1)}{P(d|h_0)} & \\times & "
"\\displaystyle\\frac{P(h_1)}{P(h_0)} \\\\[6pt] \\\\[-2pt] \\uparrow"
"                      & ~ & \\uparrow                               & ~"
"      & \\uparrow                           \\\\[6pt] \\mbox{Posterior odds}"
"         & ~ & \\mbox{\\bf{Bayes factor}}               & ~      & "
"\\mbox{Prior odds}                  \\\\ \\end{array}"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:69
msgid ""
"The Bayes factor (sometimes abbreviated as **BF**) has a special place in "
"Bayesian hypothesis testing, because it serves a similar role to the "
"*p*-value in orthodox hypothesis testing. The Bayes factor quantifies the "
"strength of evidence provided by the data, and as such it is the Bayes "
"factor that people tend to report when running a Bayesian hypothesis test. "
"The reason for reporting Bayes factors rather than posterior odds is that "
"different researchers will have different priors. Some people might have a "
"strong bias to believe the null hypothesis is true, others might have a "
"strong bias to believe it is false. Because of this, the polite thing for an"
" applied researcher to do is report the Bayes factor. That way, anyone "
"reading the paper can multiply the Bayes factor by their own *personal* "
"prior odds, and they can work out for themselves what the posterior odds "
"would be. In any case, by convention we like to pretend that we give equal "
"consideration to both the null hypothesis and the alternative, in which case"
" the prior odds equals 1, and the posterior odds becomes the same as the "
"Bayes factor."
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:87
msgid "Interpreting Bayes factors"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:89
msgid ""
"One of the really nice things about the Bayes factor is the numbers are "
"inherently meaningful. If you run an experiment and you compute a Bayes "
"factor of 4, it means that the evidence provided by your data corresponds to"
" betting odds of 4:1 in favour of the alternative. However, there have been "
"some attempts to quantify the standards of evidence that would be considered"
" meaningful in a scientific context. The two most widely used are from "
"`Jeffreys (1961) <References.html#jeffreys-1961>`__ and `Kass and Raftery "
"(1995) <References.html#kass-1995>`__. Of the two, I tend to prefer the "
"`Kass and Raftery (1995) <References.html#kass-1995>`__ table because it’s a"
" bit more conservative. So here it is:"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:100
msgid "Bayes factor"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:100
msgid "Interpretation"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:102
msgid "1 - 3"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:102
msgid "Negligible evidence"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:103
msgid "3 - 20"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:103
msgid "Positive evidence"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:104
msgid "20 - 150"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:104
msgid "Strong evidence"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:105
msgid "> 150"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:105
msgid "Very strong evidence"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:108
msgid ""
"And to be perfectly honest, I think that even the `Kass and Raftery (1995) "
"<References.html#kass-1995>`__ standards are being a bit charitable. If it "
"were up to me, I’d have called the “positive evidence” category “weak "
"evidence”. To me, anything in the range 3:1 to 20:1 is “weak” or “modest” "
"evidence at best. But there are no hard and fast rules here. What counts as "
"strong or weak evidence depends entirely on how conservative you are and "
"upon the standards that your community insists upon before it is willing to "
"label a finding as “true”."
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:117
msgid ""
"In any case, note that all the numbers listed above make sense if the Bayes "
"factor is greater than 1 (i.e., the evidence favours the alternative "
"hypothesis). However, one big practical advantage of the Bayesian approach "
"relative to the orthodox approach is that it also allows you to quantify "
"evidence *for* the null. When that happens, the Bayes factor will be less "
"than 1. You can choose to report a Bayes factor less than 1, but to be "
"honest I find it confusing. For example, suppose that the likelihood of the "
"data under the null hypothesis *P*\\ (d|h\\ :sub:`0`) is equal to 0.2, and "
"the corresponding likelihood *P*\\ (d|h\\ :sub:`1`) under the alternative "
"hypothesis is 0.1. Using the equations given above, Bayes factor here would "
"be"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:129
msgid "\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:131
msgid ""
"Read literally, this result tells is that the evidence in favour of the "
"alternative is 0.5 to 1. I find this hard to understand. To me, it makes a "
"lot more sense to turn the equation “upside down”, and report the amount op "
"evidence in favour of the *null*. In other words, what we calculate is this"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:137
msgid "\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2"
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:139
msgid ""
"And what we would report is a Bayes factor of 2:1 in favour of the null. "
"Much easier to understand, and you can interpret this using the table above."
msgstr ""

#: ../../lsj/Ch16_Bayes_2.rst:146
msgid ""
"Obviously, this is a highly simplified story. All the complexity of real "
"life Bayesian hypothesis testing comes down to how you calculate the "
"likelihood *P*\\ (d|h) when the hypothesis *h* is a complex and vague thing."
" I’m not going to talk about those complexities in this book, but I do want "
"to highlight that although this simple story is true as far as it goes, real"
" life is messier than I’m able to cover in an introductory stats textbook."
msgstr ""
