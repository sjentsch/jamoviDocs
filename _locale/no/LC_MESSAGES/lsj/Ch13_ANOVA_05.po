# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The section authors, The jamovi Group, and Sebastian Jentschke (curating this documentation). This work is licensed under a Creative Commons Attribution-Non Commercial 4.0 International License.
# This file is distributed under the same license as the jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: jamovi\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-08-18 23:13+0200\n"
"PO-Revision-Date: 2020-08-10 17:56+0000\n"
"Language-Team: Norwegian Bokmål (https://www.transifex.com/jamovi/teams/111618/nb/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: nb\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: ../../lsj/Ch13_ANOVA_05.rst:4
msgid "Multiple comparisons and post-hoc tests"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:6
msgid ""
"Any time you run an ANOVA with more than two groups and you end up with a "
"significant effect, the first thing you’ll probably want to ask is which "
"groups are actually different from one another. In our drugs example, our "
"null hypothesis was that all three drugs (placebo, Anxifree and Joyzepam) "
"have the exact same effect on mood. But if you think about it, the null "
"hypothesis is actually claiming *three* different things all at once here. "
"Specifically, it claims that:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:14
msgid ""
"Your competitor’s drug (Anxifree) is no better than a placebo (i.e., µ\\ "
":sub:`A` = µ\\ :sub:`P`)"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:17
msgid ""
"Your drug (Joyzepam) is no better than a placebo (i.e., µ\\ :sub:`J` = µ\\ "
":sub:`P`)"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:20
msgid ""
"Anxifree and Joyzepam are equally effective (i.e., µ\\ :sub:`J` = µ\\ "
":sub:`A`)"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:23
msgid ""
"If any one of those three claims is false, then the null hypothesis is also "
"false. So, now that we’ve rejected our null hypothesis, we’re thinking that "
"*at least* one of those things isn’t true. But which ones? All three of "
"these propositions are of interest. Since you certainly want to know if your"
" new drug Joyzepam is better than a placebo, it would be nice to know how "
"well it stacks up against an existing commercial alternative (i.e., "
"Anxifree). It would even be useful to check the performance of Anxifree "
"against the placebo. Even if Anxifree has already been extensively tested "
"against placebos by other researchers, it can still be very useful to check "
"that your study is producing similar results to earlier work."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:35
msgid ""
"When we characterise the null hypothesis in terms of these three distinct "
"propositions, it becomes clear that there are eight possible “states of the "
"world” that we need to distinguish between:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:40
msgid "possibility:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`A`"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`J`"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:40
msgid "which hypothesis?"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:43 ../../lsj/Ch13_ANOVA_05.rst:207
msgid "1"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:43 ../../lsj/Ch13_ANOVA_05.rst:43
#: ../../lsj/Ch13_ANOVA_05.rst:43 ../../lsj/Ch13_ANOVA_05.rst:45
#: ../../lsj/Ch13_ANOVA_05.rst:45 ../../lsj/Ch13_ANOVA_05.rst:47
#: ../../lsj/Ch13_ANOVA_05.rst:47 ../../lsj/Ch13_ANOVA_05.rst:49
#: ../../lsj/Ch13_ANOVA_05.rst:49 ../../lsj/Ch13_ANOVA_05.rst:51
#: ../../lsj/Ch13_ANOVA_05.rst:53 ../../lsj/Ch13_ANOVA_05.rst:55
msgid "✓"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:43
msgid "null"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:45 ../../lsj/Ch13_ANOVA_05.rst:206
msgid "2"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:45 ../../lsj/Ch13_ANOVA_05.rst:47
#: ../../lsj/Ch13_ANOVA_05.rst:49 ../../lsj/Ch13_ANOVA_05.rst:51
#: ../../lsj/Ch13_ANOVA_05.rst:53 ../../lsj/Ch13_ANOVA_05.rst:55
#: ../../lsj/Ch13_ANOVA_05.rst:57
msgid "alternative"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:47 ../../lsj/Ch13_ANOVA_05.rst:205
msgid "3"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:49 ../../lsj/Ch13_ANOVA_05.rst:204
msgid "4"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:51 ../../lsj/Ch13_ANOVA_05.rst:203
msgid "5"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:53
msgid "6"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:55
msgid "7"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:57
msgid "8"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:60
msgid ""
"By rejecting the null hypothesis, we’ve decided that we *don’t* believe that"
" #1 is the true state of the world. The next question to ask is, which of "
"the other seven possibilities *do* we think is right? When faced with this "
"situation, its usually helps to look at the data. For instance, if we look "
"at the plots in :numref:`fig-anova1`, it’s tempting to conclude that "
"Joyzepam is better than the placebo and better than Anxifree, but there’s no"
" real difference between Anxifree and the placebo. However, if we want to "
"get a clearer answer about this, it might help to run some tests."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:71
msgid "Running “pairwise” *t*-tests"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:73
msgid ""
"How might we go about solving our problem? Given that we’ve got three "
"separate pairs of means (placebo versus Anxifree, placebo versus Joyzepam, "
"and Anxifree versus Joyzepam) to compare, what we could do is run three "
"separate *t*-tests and see what happens. This is easy to do in jamovi. Go to"
" the ANOVA ‘Post Hoc Tests’ options, move the ‘drug’ variable across into "
"the active box on the right, and then click on the ‘No correction’ checkbox."
" This will produce a neat table showing all the pairwise *t*-test "
"comparisons amongst the three levels of the ``drug`` variable, as in :numref"
":`fig-anova3`."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:89
msgid "Uncorrected pairwise t-tests as post-hoc comparisons in jamovi"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:94
msgid "Corrections for multiple testing"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:96
msgid ""
"In the previous section I hinted that there’s a problem with just running "
"lots and lots of *t*-tests. The concern is that, when running these "
"analyses, what we’re doing is going on a “fishing expedition”. We’re running"
" lots and lots of tests without much theoretical guidance in the hope that "
"some of them come up significant. This kind of theory-free search for group "
"differences is referred to as **post-hoc analysis** (“post-hoc” being Latin "
"for “after this”).\\ [#]_"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:104
msgid ""
"It’s okay to run post-hoc analyses, but a lot of care is required. For "
"instance, the analysis that I ran in the previous section should be avoided,"
" as each *individual* *t*-test is designed to have a 5% Type I error rate "
"(i.e., *α* = 0.05) and I ran three of these tests. Imagine what would have "
"happened if my ANOVA involved 10 different groups, and I had decided to run "
"45 “post-hoc” *t*-tests to try to find out which ones were significantly "
"different from each other, you’d expect 2 or 3 of them to come up "
"significant *by chance alone*. As we saw in Chapter `Hypothesis testing "
"<Ch09_HypothesisTesting.html#hypothesis-testing>`__, the central organising "
"principle behind null hypothesis testing is that we seek to control our Type"
" I error rate, but now that I’m running lots of *t*-tests at once in order "
"to determine the source of my ANOVA results, my actual Type I error rate "
"across this whole *family* of tests has gotten completely out of control."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:120
msgid ""
"The usual solution to this problem is to introduce an adjustment to the "
"*p*-value, which aims to control the total error rate across the family of "
"tests (`Shaffer, 1995 <References.html#shaffer-1995>`__\\ ). An adjustment "
"of this form, which is usually (but not always) applied because one is doing"
" post-hoc analysis, is often referred to as a **correction for multiple "
"comparisons**, though it is sometimes referred to as “simultaneous "
"inference”. In any case, there are quite a few different ways of doing this "
"adjustment. I’ll discuss a few of them in this section and in Section `Post-"
"hoc tests <Ch14_ANOVA2_08.html#post-hoc-tests>`__, but you should be aware "
"that there are many other methods out there (`Hsu, 1996 "
"<References.html#hsu-1996>`__\\ )."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:132
msgid "Bonferroni corrections"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:134
msgid ""
"The simplest of these adjustments is called the **Bonferroni correction** "
"(`Dunn, 1961 <References.html#dunn-1961>`__\\ ), and it’s very very simple "
"indeed. Suppose that my post-hoc analysis consists of *m* separate tests, "
"and I want to ensure that the total probability of making *any* Type I "
"errors at all is at most *α*.\\ [#]_ If so, then the Bonferroni correction "
"just says “multiply all your raw *p*-values by *m*”. If we let *p* denote "
"the original *p*-value, and let *p*'\\ :sub:`j` be the corrected value, then"
" the Bonferroni correction tells that:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:144
msgid "*p*'\\ :sub:`j` = *m* × *p*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:146
msgid ""
"And therefore, if you’re using the Bonferroni correction, you would reject "
"the null hypothesis if *p*'\\ :sub:`j` < *α*. The logic behind this "
"correction is very straightforward. We’re doing *m* different tests, so if "
"we arrange it so that each test has a Type I error rate of at most *α* / "
"*m*, then the *total* Type I error rate across these tests cannot be larger "
"than *α*. That’s pretty simple, so much so that in the original paper, the "
"author writes,"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:154
msgid ""
"The method given here is so simple and so general that I am sure it must "
"have been used before this. I do not find it, however, so can only conclude "
"that perhaps its very simplicity has kept statisticians from realizing that "
"it is a very good method in some situations (`Dunn, 1961 "
"<References.html#dunn-1961>`__\\ , pp. 52-53)."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:160
msgid ""
"To use the Bonferroni correction in jamovi, just click on the ‘Bonferroni’ "
"checkbox in the ‘Correction’ options, and you will see another column added "
"to the ANOVA results table showing the adjusted *p*-values for the "
"Bonferroni correction (:numref:`fig-anova3`). If we compare these three "
"*p*-values to those for the uncorrected, pairwise *t*-tests, it is clear "
"that the only thing that jamovi has done is multiply them by 3."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:169
msgid "Holm corrections"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:171
msgid ""
"Although the Bonferroni correction is the simplest adjustment out there, "
"it’s not usually the best one to use. One method that is often used instead "
"is the **Holm correction** (`Holm, 1979 <References.html#holm-1979>`__\\ ). "
"The idea behind the Holm correction is to pretend that you’re doing the "
"tests sequentially, starting with the smallest (raw) *p*-value and moving "
"onto the largest one. For the *j*-th largest of the *p*-values, the "
"adjustment is *either*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:179
msgid "*p*'\\ :sub:`j` = j × *p*\\ :sub:`j`"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:181
msgid ""
"(i.e., the biggest *p*-value remains unchanged, the second biggest *p*-value"
" is doubled, the third biggest *p*-value is tripled, and so on), *or*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:185
msgid "*p*'\\ :sub:`j` = *p*'\\ :sub:`j + 1`"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:187
msgid ""
"whichever one is larger. This might sound a little confusing, so let’s go "
"through it a little more slowly. Here’s what the Holm correction does. "
"First, you sort all of your *p*-values in order, from smallest to largest. "
"For the smallest *p*-value all you do is multiply it by *m*, and you’re "
"done. However, for all the other ones it’s a two-stage process. For "
"instance, when you move to the second smallest *p* value, you first multiply"
" it by *m* - 1. If this produces a number that is bigger than the adjusted "
"*p*-value that you got last time, then you keep it. But if it’s smaller than"
" the last one, then you copy the last *p*-value. To illustrate how this "
"works, consider the table below, which shows the calculations of a Holm "
"correction for a collection of five *p*-values:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:201
msgid "raw *p* rank"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:201
msgid "*j*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:201
msgid "*p* × *j*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:201
msgid "Holm *p*"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:203
msgid ".001"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:203 ../../lsj/Ch13_ANOVA_05.rst:203
msgid "0.005"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:204
msgid ".005"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:204 ../../lsj/Ch13_ANOVA_05.rst:204
msgid "0.020"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:205
msgid ".019"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:205 ../../lsj/Ch13_ANOVA_05.rst:205
#: ../../lsj/Ch13_ANOVA_05.rst:206
msgid "0.057"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:206
msgid ".022"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:206
msgid "0.044"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:207
msgid ".103"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:207 ../../lsj/Ch13_ANOVA_05.rst:207
msgid "0.103"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:210
msgid "Hopefully that makes things clear."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:212
msgid ""
"Although it’s a little harder to calculate, the Holm correction has some "
"very nice properties. It’s more powerful than Bonferroni (i.e., it has a "
"lower Type II error rate) but, counter-intuitive as it might seem, it has "
"the *same* Type I error rate. As a consequence, in practice there’s never "
"any reason to use the simpler Bonferroni correction since it is always "
"outperformed by the slightly more elaborate Holm correction. Because of "
"this, the Holm correction should be your *go to* multiple comparison "
"correction. :numref:`fig-anova3` also shows the Holm corrected *p*-values "
"and, as you can see, the biggest *p*-value (corresponding to the comparison "
"between Anxifree and the placebo) is unaltered. At a value of 0.15, it is "
"exactly the same as the value we got originally when we applied no "
"correction at all. In contrast, the smallest *p*-value (Joyzepam versus "
"placebo) has been multiplied by three."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:227
msgid "Writing up the post-hoc test"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:229
msgid ""
"Finally, having run the post-hoc analysis to determine which groups are "
"significantly different to one another, you might write up the result like "
"this:"
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:233
msgid ""
"Post-hoc tests (using the Holm correction to adjust *p*) indicated that "
"Joyzepam produced a significantly larger mood change than both Anxifree (*p*"
" = 0.001) and the placebo (*p* = 9.0 · 10\\ :sup:`-5`). We found no evidence"
" that Anxifree performed better than the placebo (*p* = 0.15)."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:239
msgid ""
"Or, if you don’t like the idea of reporting exact *p*-values, then you’d "
"change those numbers to *p* < 0.001`, *p* < 0.01 and *p* > 0.05 "
"respectively. Either way, the key thing is that you indicate that you used "
"Holm’s correction to adjust the *p*-values. And of course, I’m assuming that"
" elsewhere in the write up you’ve included the relevant descriptive "
"statistics (i.e., the group means and standard deviations), since these "
"*p*-values on their own aren’t terribly informative."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:251
msgid ""
"If you *do* have some theoretical basis for wanting to investigate some "
"comparisons but not others, it’s a different story. In those circumstances "
"you’re not really running “post-hoc” analyses at all, you’re making “planned"
" comparisons”. I do talk about this situation later in the book in Section "
"`The method of planned comparisons <Ch14_ANOVA2_09.html#the-method-of-"
"planned-comparisons>`__), but for now I want to keep things simple."
msgstr ""

#: ../../lsj/Ch13_ANOVA_05.rst:260
msgid ""
"It’s worth noting in passing that not all adjustment methods try to do this."
" What I’ve described here is an approach for controlling “family wise Type I"
" error rate”. However, there are other post-hoc tests that seek to control "
"the “false discovery rate”, which is a somewhat different thing."
msgstr ""
